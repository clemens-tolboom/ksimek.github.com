<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Sightations</title>
 <link href="http://ksimek.github.com/atom.xml" rel="self"/>
 <link href="http://ksimek.github.com"/>
 <updated>2012-07-30T23:30:00-07:00</updated>
 <id>http://ksimek.github.com</id>
 <author>
   <name>Kyle Simek</name>
   <email>ksimek@email.arizona.edu</email>
 </author>

 
 <entry>
   <title>The Perspective Camera - An Interactive Tour</title>
   <link href="http://ksimek.github.com/2012/07/29/introduction"/>
   <updated>2012-07-29T00:00:00-07:00</updated>
   <id>http://ksimek.github.com/2012/07/29/introduction</id>
   <content type="html">&lt;p&gt;On September 27, 1998 a yellow line appeared across the gridiron during an otherwise ordinary football game between the Cincinnati Bengals and the Baltimore Ravens.  It had been added by a computer that analyzed the camera's position and the shape of the ground in real-time in order to overlay thin yellow strip onto the field.  The line marked marked the position of the next first-down, but it also marked the beginning of a new era of computer vision in live sports, from &lt;a href=&quot;http://www.youtube.com/watch?v=p-y7N-giirQ&quot;&gt;computerized pitch analysis&lt;/a&gt; in baseball to &lt;a href=&quot;http://www.youtube.com/watch?v=Cgeb61VIKvo&quot;&gt;automatic line-refs&lt;/a&gt; in tennis.&lt;/p&gt;

&lt;p&gt;In 2006, researchers from Microsoft and the University of Washington &lt;a href=&quot;http://www.youtube.com/watch?v=IgBQCoEfiMs&quot;&gt;automatically constructed a 3D tour of the Trevi Fountain in Rome&lt;/a&gt; using only images obtained by searching Flickr for &quot;trevi AND rome.&quot;&lt;/p&gt;

&lt;p&gt;In 2007, Carnegie Mellon PhD student Johnny Lee &lt;a href=&quot;http://www.youtube.com/watch?v=Jd3-eiid-Uw&quot;&gt;hacked a $40 Nintento Wii-mote&lt;/a&gt; into an impressive head-tracking virtual reality interface.&lt;/p&gt;

&lt;p&gt;In 2010, &lt;a href=&quot;http://en.wikipedia.org/wiki/Kinect&quot;&gt;Microsoft released the Kinect&lt;/a&gt;, a consumer stereo camera that rivaled the functionality of compititors sold for ten times its price, which continues to disrupt the worlds of both gaming and computer vision.&lt;/p&gt;

&lt;p&gt;What do all of these technologies have in common?  They all require a precise understanding of how the pixels in a 2D image relate to the 3D world they represent.  In other words, they all hinge on a strong camera model.  This is the first in a series of articles that explores the most commonly used camera model in computer vision: the perspective camera.  We'll start by deconstructing the perspective camera to show how each of its parts affect the rendering of a 3D scene.  Next, we'll describe how to import your calibrated camera into OpenGL to render virtual objects into a real image.  Finally, we'll show how to use your perspective camera to implement rendering in a virtual-reality system, complete with stereo rendering and head-tracking.&lt;/p&gt;

&lt;!--more--&gt;


&lt;p&gt;This series of articles is intended as a supplement to a more rigorous treatment available in several excellent textbooks.  I will focus on providing what textbooks generally don't provide: interactive demos, runnable code, and practical advice on implementation.    I will assume the reader has a basic understanding of 3D graphics and OpenGL, as well as some background in computer vision.  In other words, if you've never heard of homogeneous coordinates or a camera matrix, you might want to start with an introductory book on computer vision or at least have one handy.  I highly recommend &lt;a href=&quot;http://www.amazon.com/Multiple-View-Geometry-Computer-Vision/dp/0521540518/ref=sr_1_fkmr1_1?ie=UTF8&amp;amp;qid=1343611611&amp;amp;sr=8-1-fkmr1&amp;amp;keywords=harley+and+zisserman&quot;&gt;Multiple View Geometry in Computer Vision&lt;/a&gt; by Hartley and Zisserman, from which I borrow mathematical notation and conventions (e.g. column vectors, right-handed coordinates, etc.)&lt;/p&gt;

&lt;h2&gt;Technical Requirements&lt;/h2&gt;

&lt;p&gt;Equations in these articles are typeset using MathJax, which won't display if you've disabled JavaScript or &lt;a href=&quot;http://www.mathjax.org/resources/browser-compatibility/&quot;&gt;are using a browser that is woefully out of date&lt;/a&gt; (sorry IE 5 users).  If everything is working, you should see a matrix below:&lt;/p&gt;

&lt;div&gt;
\[
\left (
\begin{array}{c c c}
a^2 &amp;  b^2 &amp; c^2 \\
d^2 &amp;  e^2 &amp; f^2 \\
g^2 &amp;  h^2 &amp; i^2
\end{array}
\right )
\]
&lt;/div&gt;


&lt;p&gt;3D interactive demos are provided by &lt;a href=&quot;https://github.com/mrdoob/three.js/&quot;&gt;three.js&lt;/a&gt;, which also needs JavaScript and prefers a browser that supports WebGL (&lt;a href=&quot;Google%20Chrome&quot;&gt;htto://google.com/chrome&lt;/a&gt; works great, as does &lt;a href=&quot;http://www.mozilla.org/en-US/firefox/fx/#desktop&quot;&gt;the latest version of Firefox&lt;/a&gt;).  Older browsers will render using canvas, which will run slowly, look ugly, and hurl vicious insults at you.  But it should work.   If you see two spheres below, you're in business.&lt;/p&gt;

&lt;script&gt;

    requestAnimFrame = (function(){
      return  window.requestAnimationFrame       || 
              window.webkitRequestAnimationFrame || 
              window.mozRequestAnimationFrame    || 
              window.oRequestAnimationFrame      || 
              window.msRequestAnimationFrame     || 
              function( callback ){
                window.setTimeout(callback, 1000 / 60);
              };
    })();

    var $container;
    var mouseDX = 0, mouseDY = 0;
    var mouseDownX, mouseDownY;
    var x0, y0, s, fx, fy;
    var rot_y, tx, ty, tz;

    // set the scene size
    var WIDTH = 400,
      HEIGHT = 300;

    // set some camera attributes
    var VIEW_ANGLE = 45,
      ASPECT = WIDTH / HEIGHT,
      NEAR = 0.1,
      FAR = 10000;

    // get the DOM element to attach to
    // - assume we've got jQuery to hand

    // create a WebGL renderer, camera
    // and a scene
    var renderer = new THREE.WebGLRenderer();
//            var renderer = new THREE.CanvasRenderer();

    moveParameter = moveCameraCenter;
    //moveParameter = moveCameraPP;
    //moveParameter = zoomCamera;

    var default_focal = HEIGHT / 2 / Math.tan(VIEW_ANGLE * Math.PI / 360);
    var camera =
      new THREE.CalibratedCamera(
        default_focal, default_focal,
        0, 0,
        0,
        WIDTH,
        HEIGHT,
        NEAR,
        FAR);

    var scene = new THREE.Scene();

    // add the camera to the scene
    scene.add(camera);

    // the camera starts at 0,0,0
    // so pull it back
    camera.position.z = 300;

    // start the renderer
    renderer.setSize(WIDTH, HEIGHT);

    // set up the sphere vars
    var radius = 50,
        segments = 16,
        rings = 16;

    // create the sphere's material
    var sphereMaterial =
      new THREE.MeshLambertMaterial(
        {
          color: 0xCC0000
        });

    var sphere2Material =
      new THREE.MeshLambertMaterial(
        {
          color: 0x00CC00
        });

    var sphere = new THREE.Mesh(

      new THREE.SphereGeometry(
        radius,
        segments,
        rings),

      sphereMaterial);

    var sphere2 = new THREE.Mesh(

      new THREE.SphereGeometry(
        radius,
        segments,
        rings),

      sphere2Material);

    sphere2.position.z -= 100;
    sphere2.position.x -= 100;

    // add the sphere to the scene
    scene.add(sphere);
    scene.add(sphere2);

    // create a point light
    var pointLight =
      new THREE.PointLight(0xFFFFFF);

    // set its position
    pointLight.position.x = 10;
    pointLight.position.y = 50;
    pointLight.position.z = 130;

    // add to the scene
    scene.add(pointLight);

    function onMouseDown(event)
    {
        $container.mousemove(onMouseMove);
        $container.mouseup(onMouseUp);
        $container.mouseout(onMouseOut);

        mouseDownX = event.screenX;
        mouseDownY = event.screenY;
    }

    function onMouseMove(event)
    {
        var mouseX = event.screenX;
        var mouseY = event.screenY;
        
        var mouseDX = mouseX - mouseDownX;
        var mouseDY = mouseY - mouseDownY;

        moveParameter(mouseDX, mouseDY);
        render();
    }


    function onMouseOut(event)
    {
        removeListeners();
    }

    function onMouseUp(event)
    {
        removeListeners();
    }

    function removeListeners()
    {
        $container.unbind( 'mousemove');
        $container.unbind( 'mouseup');
        $container.unbind( 'mouseout');
    }

    function onTouchStart(event)
    {
        if ( event.touches.length == 1 ) {

            event.preventDefault();

            mouseDownX = event.touches[ 0 ].pageX;
            mouseDownY = event.touches[ 0 ].pageY;
        }
    }

    function onTouchMove(event)
    {
        if ( event.touches.length == 1 ) {

            event.preventDefault();

            var mouseX = event.touches[ 0 ].pageX;
            var mouseY = event.touches[ 0 ].pageY;

            var mouseDX = mouseX - mouseDownX;
            var mouseDY = mouseY - mouseDownY;

            moveParameter(mouseDX, mouseDY);
            render();
        }
    }

    function zoomCamera(param1, param2)
    {
        camera.fx = default_focal + 2*param2;
        camera.fy = default_focal + 2*param2;
        camera.s = -2*param1;
        camera.updateProjectionMatrix();
    }

    // move camera's principal point
    function moveCameraPP(param1, param2)
    {
        camera.x0 = param1;
        camera.y0 = -param2;
        camera.updateProjectionMatrix();
    }

    function moveCameraCenter(param1, param2)
    {
        camera.position.x =  param1;
        camera.position.y = -param2;
    }

    function animLoop() 
    {
        requestAnimFrame(animLoop);
        render();
    }

    function render()
    {
        renderer.render(scene, camera);
    }


    // attach the render-supplied DOM element
    $(document).ready(function(){
        $container = $('#3d_container');
        $container.append(renderer.domElement);

        $container.mousedown(onMouseDown);
        $container.bind( 'touchstart', onTouchStart);
        $container.bind( 'touchmove', onTouchMove);

        render();
    });

&lt;/script&gt;




&lt;div id=&quot;3d_container&quot;&gt;
&lt;/div&gt;


&lt;h2&gt;Table of Contents&lt;/h2&gt;

&lt;p&gt;Below is a list of all the articles in this series.  New articles will be added to this list as I post them, so you can always return to this page for an up-to-date listing.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Dissecting the Camera Matrix, Part 1: Intrinsic/Extrinsic Decomposition&lt;/li&gt;
&lt;li&gt;Dissecting the Camera Matrix, Part 2: The Extrinsic Matrix&lt;/li&gt;
&lt;li&gt;Dissecting the Camera Matrix, Part 3: The Intrinsic Matrix&lt;/li&gt;
&lt;li&gt;Simulating your Calibrated Camera in OpenGL&lt;/li&gt;
&lt;li&gt;Stereo Rendering &quot;the Right Way&quot; using a Calibrated Camera&lt;/li&gt;
&lt;li&gt;Virtual Reality Head Tracking using a Calibrated Camera&lt;/li&gt;
&lt;/ul&gt;


&lt;!--
* Pixel-perfect Backprojected Textures
* Rendering a Pixel-Perfect Image Plane
--&gt;

</content>
 </entry>
 
 
</feed>